---
layout: page
title: Reading resources
---
A page to curate recent papers, tutorials, code releases and news articles.

# Contents
* [Papers](#papers)
* [Projects](#projects)
* [Datasets](#datasets)
* [Coding/Software](#coding-software)
* [Tutorials](#tutorials)
* [Talks](#talks)
* [Review articles](#review)
* [News articles/ blogs](#news-blogs)

* * *

## Papers
- **Spherical U-Net on Cortical Surfaces: Methods and Applications** (2019), Zhao et al. [[pdf]](http://arxiv.org/pdf/1503.02531) [[code]](https://github.com/zhaofenqiang/Spherical_U-Net)

This paper addresses the drawbacks of applying CNNs to spherical topologies such as those seen in medical imaging structures by proposing a novel convolution filter analogous to the standard convolution on the image grid. A Spherical U-Net architecture is developed which replaces all operations in the standard U-Net with their spherical operation counterparts.

- **Black Magic in Deep Learning: How Human Skill Impacts Network Training** (2020), Anand et al. [[pdf]](https://arxiv.org/abs/2008.05981) [[code]](https://github.com/anandkanav92/htune)

This paper presents an initial study to assess how a user's prior experience with deep learning impact accuracy. The results show a strong positive correlation between the participant's experience and the final performance. They additionally indicate that an experienced participant finds better solutions using fewer resources on average.

- **Knowing what you know in brain segmentation using Bayesian deep neural net** (2019), McClure et al. [[pdf]](https://arxiv.org/abs/1812.01719) [[code]](https://github.com/neuronets/kwyk)

In this paper, a Bayesian deep neural network (DNN) is proposed for predicting FreeSurfer segmentations of structural MRI volumes. The network is trained using a novel spike-and-slab dropout-based variational inference approach and outperforms other methods in terms of similarity between the segmentation predictions and freesurfer labels.



## Projects

-[Pydra](https://github.com/nipype/pydra)

A simple dataflow engine with scalable semantics.

-[Nobrainer](https://github.com/neuronets/nobrainer)

A deep learning framework for 3D image processing of brain imaging data.


## Datasets
  
-[OpenNeuro](https://openneuro.org)

A free and open platform for sharing MRI, MEG, EEG, iEEG, and ECoG data using BIDS specification.


## Coding / Software

-[TensorFlow](https://www.tensorflow.org)

End-to-end open source platform for machine learning developed by Google.

-[DLTK](https://github.com/DLTK/DLTK)

A toolkit to enable fast prototyping with a low entry threshold and ensure reproducibility in image analysis applications, with a particular focus on medical imaging.




## Tutorials

-[Self Supervised Representation Learning](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html)

-[Deep Learning - Berkeley](https://berkeley-deep-learning.github.io/cs294-131-s17/)

-[Tensor Flow tutorials](https://github.com/chiphuyen/stanford-tensorflow-tutorials/)

-[HVass Labs-tensor flow tutorials](https://github.com/Hvass-Labs/TensorFlow-Tutorials)


## Talks

-[Timnit Gebru - TedTalk](https://www.youtube.com/watch?v=PWCtoVt1CJM)

Timnit Gebru, Co-Founder of Black in AI, talks about inherent biases in current artificial intelligence methods and how it affects communities.



## Review

-[Underspecification Presents Challenges for Credibility in Modern Machine Learning](https://arxiv.org/pdf/2011.03395.pdf)

An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. During deployment, this can lead to issues such as instability and poor model behavior in practice. This review paper shows the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.

## News / Blogs

-[Artificial Intelligence Neural Network Learns When It Should Not Be Trusted](https://scitechdaily.com/artificial-intelligence-neural-network-learns-when-it-should-not-be-trusted/)

This article discusses the potential benefits on real-world safe usage of AI caused by improvements in uncertainty estimation in AI models.

-[AlphaFold: using AI for scientific discovery](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)

AlphaFold, an AI model developed at DeepMind, used large genomic datasets to predict the 3D structure of a protein and has achieved unprecedented levels of accuracy - marking significant progress on one of the grand challenges in biology.



